{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb0J8nnEy7f5nXbntdTLzn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-caballero/Data-Discovery/blob/main/modulo3_manipulacion_datos_faltantes/Handling_Missing_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://posgrado.utec.edu.pe/sites/default/files/2023-08/Testimonial-home-2.jpg\" alt=\"HTML5 Icon\" width=\"900\" height=\"250\" >\n"
      ],
      "metadata": {
        "id": "63Z52XtzaaqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Handling Missing Data**"
      ],
      "metadata": {
        "id": "nXzKdHNnalF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objetivos**\n",
        "\n",
        "- Aplicar distintas técnicas de imputación:\n",
        "\n",
        "  - Medidas de tendencia central (media, mediana, moda)\n",
        "\n",
        "  - Imputación por regresión\n",
        "\n",
        "  - KNN imputation\n",
        "\n",
        "  - XGBoost imputador\n",
        "\n",
        "  - Autoencoders\n",
        "\n",
        "  - MICE (Multiple Imputation by Chained Equations)\n",
        "\n",
        "- Entrenar un modelo base (RandomForest o XGBoost) para comparar el impacto de cada estrategia de imputación en términos de performance (accuracy, AUC, etc.)\n",
        "\n",
        "- Reflexionar sobre las implicancias de cada método para modelos analíticos."
      ],
      "metadata": {
        "id": "l3bhQt_IalxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**\n",
        "\n",
        "Loan Prediction - train.csv\n",
        "\n",
        "Puedes obtenerlo desde:\n",
        " https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii"
      ],
      "metadata": {
        "id": "Inh96ly5azO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librerías necesarias"
      ],
      "metadata": {
        "id": "rvo1B-sea4nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy seaborn matplotlib scikit-learn xgboost fancyimpute tensorflow missingno\n"
      ],
      "metadata": {
        "id": "RPK6gi4ka6Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Carga y diagnóstico inicial"
      ],
      "metadata": {
        "id": "wOP8Iso2a8uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "df.drop(\"Loan_ID\", axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "8katKHaya_1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Medidas de tendencia central (media, mediana, moda)"
      ],
      "metadata": {
        "id": "LodYmLpGbCZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80twajk3aaHM"
      },
      "outputs": [],
      "source": [
        "df_mean = df.copy()\n",
        "\n",
        "df_mean[\"LoanAmount\"].fillna(df_mean[\"LoanAmount\"].mean(), inplace=True)\n",
        "df_mean[\"Gender\"].fillna(df_mean[\"Gender\"].mode()[0], inplace=True)\n",
        "df_mean[\"Self_Employed\"].fillna(df_mean[\"Self_Employed\"].mode()[0], inplace=True)\n",
        "df_mean[\"Dependents\"].fillna(df_mean[\"Dependents\"].mode()[0], inplace=True)\n",
        "df_mean[\"Credit_History\"].fillna(df_mean[\"Credit_History\"].mode()[0], inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Imputación por regresión lineal"
      ],
      "metadata": {
        "id": "wQLWxMqmbK1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "df_reg = df.copy()\n",
        "train = df_reg[df_reg[\"LoanAmount\"].notnull()]\n",
        "test = df_reg[df_reg[\"LoanAmount\"].isnull()]\n",
        "\n",
        "X_train = train[[\"ApplicantIncome\", \"CoapplicantIncome\"]]\n",
        "y_train = train[\"LoanAmount\"]\n",
        "X_test = test[[\"ApplicantIncome\", \"CoapplicantIncome\"]]\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "df_reg.loc[df_reg[\"LoanAmount\"].isnull(), \"LoanAmount\"] = preds\n"
      ],
      "metadata": {
        "id": "7BZ1G8k0bODa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 🔎 Imputación KNN"
      ],
      "metadata": {
        "id": "YFnm0CuwbQi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df_knn = df.copy()\n",
        "df_knn = df_knn.apply(LabelEncoder().fit_transform)\n",
        "\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "df_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(df_knn), columns=df_knn.columns)\n"
      ],
      "metadata": {
        "id": "IZtvpYFybUN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Imputación con XGBoost (modelo para imputar)"
      ],
      "metadata": {
        "id": "6BS0jGpibWTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "df_xgb = df.copy()\n",
        "\n",
        "def xgb_impute(df, target_col):\n",
        "    train = df[df[target_col].notnull()]\n",
        "    test = df[df[target_col].isnull()]\n",
        "    features = [col for col in df.columns if col != target_col and df[col].notnull().sum() > 0]\n",
        "\n",
        "    train = train.dropna(subset=features)\n",
        "    X_train = pd.get_dummies(train[features])\n",
        "    y_train = train[target_col]\n",
        "    X_test = pd.get_dummies(test[features])\n",
        "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "    model = xgb.XGBRegressor(n_estimators=100)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    df.loc[df[target_col].isnull(), target_col] = preds\n",
        "    return df\n",
        "\n",
        "df_xgb = xgb_impute(df_xgb, \"LoanAmount\")\n"
      ],
      "metadata": {
        "id": "bg-F6wCNba5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Imputación MICE (Multivariate Imputation)"
      ],
      "metadata": {
        "id": "Wu8e7VBcbc27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fancyimpute import IterativeImputer\n",
        "\n",
        "df_mice = df.copy()\n",
        "df_mice = df_mice.apply(LabelEncoder().fit_transform)\n",
        "\n",
        "mice = IterativeImputer()\n",
        "df_mice_imputed = pd.DataFrame(mice.fit_transform(df_mice), columns=df_mice.columns)\n"
      ],
      "metadata": {
        "id": "Tf_DU7a4bfZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Autoencoders para imputación"
      ],
      "metadata": {
        "id": "rUCnwkphbhF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "df_auto = df.copy()\n",
        "df_auto = df_auto.apply(LabelEncoder().fit_transform)\n",
        "df_auto = df_auto.fillna(df_auto.mean())\n",
        "\n",
        "X = df_auto.values\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X.shape[1],)),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(X.shape[1])\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X, X, epochs=100, batch_size=16, verbose=0)\n",
        "\n",
        "X_pred = model.predict(X)\n",
        "df_auto_imputed = pd.DataFrame(X_pred, columns=df_auto.columns)\n"
      ],
      "metadata": {
        "id": "vt8RT8IBbiuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Evaluación del impacto predictivo\n",
        "\n",
        "Utilizaremos un modelo de clasificación (XGBClassifier) para predecir Loan_Status con los diferentes datasets imputados."
      ],
      "metadata": {
        "id": "LdSdwVFKbm0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def evaluate_model(df, name=\"\"):\n",
        "    df = df.copy()\n",
        "    df = df.dropna()\n",
        "    X = df.drop(\"Loan_Status\", axis=1)\n",
        "    y = df[\"Loan_Status\"]\n",
        "\n",
        "    if y.dtype == 'O':\n",
        "        y = LabelEncoder().fit_transform(y)\n",
        "\n",
        "    X = pd.get_dummies(X)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    probas = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "    print(f\"🔍 Evaluación con {name}\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, preds):.4f}\")\n",
        "    print(f\"AUC: {roc_auc_score(y_test, probas):.4f}\\n\")\n",
        "\n",
        "# Evaluar\n",
        "evaluate_model(df_mean, \"Media/Moda\")\n",
        "evaluate_model(df_reg, \"Regresión\")\n",
        "evaluate_model(df_knn_imputed, \"KNN\")\n",
        "evaluate_model(df_xgb, \"XGBoost\")\n",
        "evaluate_model(df_mice_imputed, \"MICE\")\n",
        "evaluate_model(df_auto_imputed, \"Autoencoder\")\n"
      ],
      "metadata": {
        "id": "KAmNaCV7brsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preguntas para reflexión\n",
        "\n",
        "- ¿Qué técnica ofrece mejor balance entre simplicidad y precisión?\n",
        "\n",
        "- ¿Qué riesgos podría implicar usar una técnica muy compleja como Autoencoders o XGBoost para imputar?\n",
        "\n",
        "- ¿Por qué KNN puede ser sensible a la escala de los datos o a outliers?\n",
        "\n",
        "- ¿Cómo se podría incorporar la incertidumbre de la imputación en el modelo final?\n",
        "\n",
        "- ¿Qué tipo de datos (categóricos, numéricos, multivariados) favorecen el uso de MICE sobre otros métodos?"
      ],
      "metadata": {
        "id": "vDWnUyhrb44e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusión\n",
        "\n",
        "La imputación no es solo un paso técnico: es una decisión analítica que puede alterar el resultado del modelo. Evaluar diferentes métodos no solo mejora el desempeño, sino también la confianza en los modelos desarrollados. Entender cuándo usar cada técnica y su impacto es clave para un análisis responsable."
      ],
      "metadata": {
        "id": "QVfOuKovb-94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Gracias por completar este laboratorio!\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "cDjdWiDRcDSI"
      }
    }
  ]
}